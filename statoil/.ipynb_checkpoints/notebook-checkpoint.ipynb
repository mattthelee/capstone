{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def loadData(filepath):\n",
    "    with open(filepath) as Json:\n",
    "        data = pd.DataFrame(json.load(Json))\n",
    "    print \"Data loaded from\", filepath\n",
    "    return data\n",
    "\n",
    "def convertBand(band):\n",
    "    band_array = np.array(band)\n",
    "    band_array.shape = (75,75)\n",
    "    return np.asarray([band_array])\n",
    "\n",
    "def convertBands(band1,band2):\n",
    "    band1_array = np.array(band1)\n",
    "    band1_array.shape = (75,75)\n",
    "    \n",
    "    band2_array = np.array(band2)\n",
    "    band2_array.shape = (75,75)\n",
    "    return np.asarray([band1_array,band2_array])\n",
    "\n",
    "def convertToTensor(dataframe):\n",
    "    tensor = map(lambda a,b : convertBands(a,b), training_frame['band_1'], training_frame['band_2'])\n",
    "    return np.asarray(tensor)\n",
    "\n",
    "def createVGGModel():\n",
    "    anglesInput = Input(shape=[1], name =\"angles\")\n",
    "    angles_layer = Dense(1,)(anglesInput)\n",
    "    \n",
    "    transferred_model = VGG16(weights='imagenet')\n",
    "\n",
    "    \n",
    "def createModel():\n",
    "    \n",
    "    cnnModel = Sequential()\n",
    "    #If doing stuff with single channel\n",
    "    #cnnModel.add(Conv2D(64,(3,3), strides=2, input_shape=(1,75,75), data_format='channels_first'))\n",
    "    cnnModel.add(Conv2D(64,(3,3), strides=2, input_shape=(2,75,75), data_format='channels_first'))\n",
    "    cnnModel.add(Conv2D(32,(2,2),data_format='channels_first'))\n",
    "    cnnModel.add(MaxPooling2D(pool_size=(2,2),data_format='channels_first'))\n",
    "    cnnModel.add(Flatten())\n",
    "    cnnModel.add(Dense(64,activation='relu'))\n",
    "    cnnModel.add(Dense(2, activation='sigmoid')) \n",
    "    \n",
    "    cnnModel.summary()\n",
    "    cnnModel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return cnnModel\n",
    "\n",
    "def runModel(channelled_bands, y_train):\n",
    "    cnnModel = createModel()\n",
    "    return cnnModel.fit(channelled_bands,y_train, epochs=10, batch_size=20)\n",
    "\n",
    "def showArrayImage(array):\n",
    "    flat_array = array.flatten()\n",
    "    new_array = np.asarray(map(lambda v: int(v + 40), flat_array))\n",
    "    new_array.shape = (75,75)\n",
    "    arrayImage = Image.fromarray(new_array)\n",
    "    return arrayImage.show()\n",
    "    \n",
    "\n",
    "def theirconvert(training_frame):\n",
    "    X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in training_frame[\"band_1\"]])\n",
    "    X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in training_frame[\"band_2\"]])\n",
    "    X_band_3=(X_band_1+X_band_2)/2\n",
    "    X_train = np.concatenate([X_band_1[:, :, :, np.newaxis]\n",
    "                          , X_band_2[:, :, :, np.newaxis]\n",
    "                         , X_band_3[:, :, :, np.newaxis]], axis=-1)\n",
    "    return X_train\n",
    "\n",
    "def createband3(band1,band2,angle):\n",
    "    band3 = (band1 + band2)/2\n",
    "    return band3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 360)\n",
    "\n",
    "training_flow = gen.flow(x_train)\n",
    "testing_flow = gen.flow(x_test)\n",
    "\n",
    "my_model = createModel()\n",
    "my_model.fit_generator(training_flow,steps_per_epoch=24,epochs= 150)\n",
    "'''\n",
    "best_model_filepath = \"models/bestmodel.hdf5\"\n",
    "checkpointer = ModelCheckpoint(best_model_filepath,verbose=1, save_best_only= True)\n",
    "#Cross validation. Stratified cross validation is done to ensure samples are representative\n",
    "k = 3\n",
    "folds = model_selection.StratifiedKFold(n_splits=k, shuffle=True).split(x_train,y_train)\n",
    "\n",
    "folds_array = []\n",
    "batch_size = 32\n",
    "epoch_num = 150\n",
    "for i in range(k):\n",
    "    fold = folds.next()\n",
    "    cv_training_indexes = fold[0]\n",
    "    cv_testing_indexes = fold[1]\n",
    "    \n",
    "    cv_x_training_samples = [x_train[index] for index in cv_training_indexes]\n",
    "    cv_y_training_samples = [y_train[index] for index in cv_training_indexes]\n",
    "    \n",
    "    cv_x_testing_samples = [x_train[index] for index in cv_testing_indexes]\n",
    "    cv_y_testing_samples = [y_train[index] for index in cv_testing_indexes]\n",
    "    \n",
    "    cv_train_angle_factor = [angle_factor[index] for index in cv_training_indexes]\n",
    "    cv_test_angle_factor = [angle_factor[index] for index in cv_testing_indexes]\n",
    "\n",
    "    cv_gen_train_flow = gen_flow_for_two_inputs(cv_x_training_samples,cv_train_angle_factor,cv_y_training_samples,batch_size)\n",
    "    model = createCombinedModel()\n",
    "    model.fit_generator(cv_gen_train_flow,steps_per_epoch=32, epochs=epoch_num, callbacks= [checkpointer], validation_data = ([cv_x_testing_samples,cv_test_angle_factor], cv_y_testing_samples),verbose =1)\n",
    "   \n",
    "\n",
    "model = createCombinedModel()\n",
    "model.load_weights(best_model_filepath)\n",
    "print \"training score\"\n",
    "gen_train_flow = gen_flow_for_two_inputs(x_train,angle_factor,y_train,batch_size)\n",
    "\n",
    "train_result = model.evaluate_generator(gen_train_flow)\n",
    "print train_result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Below has all the imports needed and gets the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Nov  4 17:05:40 2017\n",
    "\n",
    "@author: leem\n",
    "\"\"\"\n",
    "\n",
    "# need to find a sensible way to import the data. \n",
    "# Would like to handle the data in something like a datframe \n",
    "# am i able to load all the data into memory\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from sklearn import model_selection\n",
    "#import png\n",
    "\n",
    "def frameToImagesTensor(training_frame):\n",
    "    X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in training_frame[\"band_1\"]])\n",
    "    X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in training_frame[\"band_2\"]])\n",
    "    X_band_3=(X_band_1+X_band_2)/2\n",
    "    #X_band_3 = map(lambda band1, band2: createband3(band1,band2), X_band_1,X_band_2)\n",
    "    X_train = np.concatenate([X_band_1[:, :, :, np.newaxis]\n",
    "                          , X_band_2[:, :, :, np.newaxis]\n",
    "                         , X_band_3[:, :, :, np.newaxis]], axis=-1)\n",
    "    return X_train\n",
    "\n",
    "training_frame = pd.read_json(\"data/processed/train.json\")\n",
    "testing_frame = pd.read_json(\"data/processed/test.json\")\n",
    "y_train = training_frame['is_iceberg']\n",
    "\n",
    "avg_angle = np.mean(filter(lambda x: x != 'na' ,training_frame['inc_angle']))\n",
    "\n",
    "# Replace the na's with the average angle\n",
    "training_frame['inc_angle'] = training_frame['inc_angle'].replace('na',avg_angle)\n",
    "\n",
    "# have to convert y_train to a numpy array as dataframe has a keras bug\n",
    "#y_train = np.asarray(pd.get_dummies(training_frame['is_iceberg']))\n",
    "\n",
    "# Converting angle to a sin as the \n",
    "angle_factor = [ np.sin(angle*np.pi/180.0) for angle in training_frame['inc_angle']]\n",
    "\n",
    "#band_1_arrays = np.asarray(map(lambda v : convertBand(v), training_frame['band_1']))\n",
    "#band_2_arrays = np.asarray(map(lambda v : convertBand(v), training_frame['band_2']))\n",
    "#channelled_bands = convertToTensor(training_frame,angle_factor)\n",
    "\n",
    "# TODO experiment without horizontal, vertical and rotations\n",
    "# Sun direction might affect the light see so might not want to lose that information\n",
    "\n",
    "# Als0 need to check that having it as a channel isn't just something done for different colours as the polarization is a bit different\n",
    "\n",
    "x_train = frameToImagesTensor(training_frame)\n",
    "x_test = frameToImagesTensor(testing_frame)\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_flow_for_two_inputs(x,angle_factor,y, batch_size):\n",
    "    # This function is used because the NN will only take a generator as an input\n",
    "    # because we are using an genrerator to alter the main images\n",
    "    # therefore the angle_factor needs to be passed in the same way a generator would\n",
    "    # to do this we create two generators and take the output of the angle genrator as the second input\n",
    "    gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 360)\n",
    "    gen_x = gen.flow(x,y,batch_size=batch_size,seed=0)\n",
    "    gen_angle =  gen.flow(x,angle_factor,batch_size=batch_size, seed=0)\n",
    "    #TODO see if i can improve on the example also need to reference this function\n",
    "    while True:\n",
    "        x1i = gen_x.next()\n",
    "        x2i = gen_angle.next()\n",
    "        yield [x1i[0], x2i[1], x1i[1]]\n",
    "        \n",
    "\n",
    "def createCombinedModel():\n",
    "    angle_input = Input(shape=[1], name=\"angle_input\")\n",
    "    angle_layer = Dense(1,)(angle_input)\n",
    "    \n",
    "    # Use a transfer model for the initial layers\n",
    "    transfer_model = VGG16(weights='imagenet', include_top=False, input_shape=x_train.shape[1:])\n",
    "    # Get the output of the last layer of transfer model. Will need to change this for each transfer model\n",
    "    transfer_output = transfer_model.get_layer('block5_pool').output\n",
    "    transfer_output = GlobalMaxPooling2D()(transfer_output)\n",
    "    #TODO fix issue where this gives something different to angle_layer and transfer_ouput, should be a tensor\n",
    "    combined_inputs = concatenate([transfer_output, angle_layer])\n",
    "    \n",
    "    combined_model = Dense(32, activation='relu', name=\"FirstFCDense\")(combined_inputs)\n",
    "    predictions = Dense(1, activation='sigmoid',name=\"OutputDense\")(combined_model)\n",
    "    \n",
    "    model = Model(input=[transfer_model.input, angle_input], output =predictions)\n",
    "    model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# immediate steps\n",
    " # Create model with inputs for images and for angle. \n",
    " # evaluate the model, check its accuracy etc\n",
    " # evaulate for the test data\n",
    "    \n",
    "\n",
    "#immediate steps for kernal based stuff\n",
    "# Need to remind myself what form the data is in when i pass it to the model\n",
    "# need to convert daata into a flow and the pass into image generator\n",
    "# need to pass data into the model\n",
    "\n",
    "# Next steps:\n",
    "# icebergs and ships are only a few pixels wide\n",
    "# L- should therefore have the image cropped to only an area that contains the object\n",
    "# L- this will reduce redundent data and speed up the algorithm see: http://elib.dlr.de/99079/2/2016_BENTES_Frost_Velotto_Tings_EUSAR_FP.pdf\n",
    "# should do a 3d plot of the array too as shown in above paper\n",
    "# Add in image gerneator and use it to create additional images with distortions\n",
    "# use vg16 pretrained nn to help, also try the other ones available from image net\n",
    "# Setup an aws instance to allow the models to be long running\n",
    "# consider writing in pyspark compatible format\n",
    "# Add additional conv layers\n",
    "# L- research why additional conv layers would improve accuracy rather than improve performance\n",
    "# could consider looking at ship wake as form of detection\n",
    "# the higher the wind, the more bragg scattering, the more cluttered the ocean image will be\n",
    "# the higher winds also make for improved wake detection\n",
    "# clutter decreases with incidence angle\n",
    "\n",
    "#sentinel 1 paper, can i use the following data? : At DRDC Ottawa, shore-based commercial AIS data were\n",
    "#obtained in conjunction with several RADARSAT-1 and Envisat ASAR trials [32] [34] [36], for\n",
    "#compilation of a database of more than 4000 validated ship signatures that may be used to\n",
    "#improve models of ship RCS and its variability.\n",
    "\n",
    "#Should consider chaning the dB into 0,255 similar to in Feature extraction of dual-pol SAR imagery for sea ice image segmentation I\n",
    "# I need to find the range of the decibels,set one to 0, set the highest to 255 and apply some method to split the data across the range\n",
    "# Need to check the precision of the  decibels and therefore whether this process results in loss of sig fig\n",
    "    #l- from the same paper should consider perfroming the max gradient preprocessing, it's simple and was effective for them\n",
    "\n",
    "# Should add to reading list: \n",
    "\n",
    "\n",
    "# Howell, C., Mills, J., Power, D., Youden, J., Dodge, K., Randell, C., Churchill, S., and Flett,\n",
    "#D. (2006). A multivariate approach to iceberg and ship classification in HH/HV ASAR\n",
    "#data. Proc. 2006 International Geoscience and Remote Sensing Symposium (IGARSS\n",
    "#2006). CD-ROM proceedings. 31 July to 4 Aug. 2006, Denver, USA.\n",
    "\n",
    "\n",
    "#Henschel, M.D., and Livingstone, C.E. (2006). Observation of vessel heave with airborne\n",
    "#SAR. Proc. OceanSAR 2006 – The Third Workshop on Coastal and Marine Applications\n",
    "#of SAR, St. John’s, NL, Canada, 23 to 25 October 2006.\n",
    "\n",
    "#Power, D., Youden, J., Lane, K., Randell, C., and Flett, D. (2001). Iceberg detection\n",
    "#capabilities of RADARSAT synthetic aperture radar. Canadian Journal of Remote Sensing,\n",
    "#27(5), 476-486.\n",
    "\n",
    "#Pond, S., and Pickard, G.L. (1983). Introductory Dynamical Oceanography, 2 nd Edition.\n",
    "#Pergamon Press, Toronto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
